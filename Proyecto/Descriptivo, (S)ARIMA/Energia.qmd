# Análisis del consumo de energía de la empresa PJM

## Análisis del consumo de energía de la empresa PJM

La empresa PJM es una organización de transmisión regional que coordina el movimiento de electricidad mayorista en la totalidad, o parte, de 13 estados y el Distrito de Columbia.

El análisis del consumo de energía es esencial para mejorar la eficiencia operativa, reducir costos, cumplir con regulaciones y promover la sostenibilidad, por lo cual, este proyecto analiza la serie de tiempo con el fin de encontrar variaciones en el consumo de energía de los 13 estados y el Distrito de Columbia a lo largo del tiempo, así como también descubrir posibles patrones.

A continuación se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la @fig-serietiempoenergia .

```{r}
#| label: fig-serietiempoenergia
#| fig-cap: >
#|    Gráfico de la serie de tiempo de la energía.

# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]

# Gráfico de la serie de tiempo
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
plot(energia2, main="Serie de tiempo de la energía diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energía consumida",
     cex.lab=0.4)

```

# Análisis descriptivo
```{r}
#| warning: false
#| message: false
# Librerías necesarias
library(TSstudio)
library(readxl)
library(dplyr)
library(lubridate)
library(astsa)
library(feasts)
library(fable)
library(timetk)
library(tsibble)
library(zoo)
library(xts)
library(readxl)
library(tidyverse)
library(nonlinearTseries)
library(tseriesChaos) 
library(forecast)
library(plotly)
library(dplyr)
library(parsnip)
library(rsample)
library(timetk)
library(modeltime)
library(tsibble)
library(tidymodels)
library(greybox)
library(TSA)
library(urca)
library(lmtest)
library(uroot)
library(fUnitRoots)
library(sarima)
library(TSA)
require("PolynomF")
require("forecast")
```

```{r}
#| warning: false

# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
```

Según lo observado en la serie de tiempo (@fig-serieenergia2), visualmente se tiene:

```{r}
#| label: fig-serieenergia2
#| fig-cap: >
#|    Gráfico de la verosimilitud en función del hiperparámetro lambda.

# Gráfico de la serie de tiempo
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
plot(energia2, main="Serie de tiempo de la energía diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energía consumida",
     cex.lab=0.4)
```

-   **Heterocedasticidad marginal:** Se puede observar que la varianza de cada instante en la serie es casi la misma. Al parecer no es necesario estabilizar la varianza.
-   **Tendencia:** A simple vista se observa que, a medida que pasa el tiempo la serie oscila al rededor del mismo valor, por lo tanto, no es necesario estimar la tendencia.
-   **Componente estacional:** Se observan algunos patrones que se repiten con cierta periodicidad, lo cual hace que sea necesario observar la posible presencia de componente estacional y posteriormente estimarla.

## Estabilización de la varianza marginal

Como se observa en la gráfica de la serie de tiempo no es necesario realizar una estabilización de la varianza para continuar con el análisis descriptivo, sin embargo, para comprobar esto, se hace una transformación de Box-cox para ver que tanto se estabiliza la varianza. En la @fig-boxcox1energia se observa que se sugiere una transformación dado que 1 no está contenido en el intervalo.

```{r}
#| label: fig-boxcox1energia
#| fig-cap: >
#|    Gráfico de la verosimilitud en función del hiperparámetro lambda.
MASS::boxcox(lm(energia2 ~ 1),seq(-5, 5, length = 50))
abline(v = 1, col = "red", lty = 2)
```

En la siguiente salida se puede ver que el $\lambda$ sugerido es $-0.25$, como es un número negativo, se procede a hacer la transformación Box-Cox usando logaritmo natural.

```{r}
forecast::BoxCox.lambda(energia2, method ="loglik",lower = -1, upper = 3)
```

En la @fig-boxcox1lenergia a continuación se muestra que la serie en escala logarítmica nuevamente no tiene la varianza estabilizada, dado que no se contiene al 1.

```{r}
#| label: fig-boxcox1lenergia
#| fig-cap: >
#|    Gráfico de la verosimilitud para la serie en escala logarítmica, en función del hiperparámetro lambda.
lenergia2=log(energia2)
MASS::boxcox(lm(lenergia2 ~ 1),seq(-5, 5, length =  50))
abline(v = 1, col = "red", lty = 2)
```

Además, se puede notar en la @fig-sinconboxcoxenerg , que no hay una diferencia significativa entre la serie transformada y no transformada. Por lo que el análisis descriptivo se continúa usando los datos originales.

```{r}
#| label: fig-sinconboxcoxenerg
#| fig-cap: >
#|    Serie original y serie con transformación logarítmica.
par(mar = c(1,1,1,1))
par(mfrow=c(2,1),mar=c(3,3,3,3))
plot(energia2,main="Serie energía sin Transformar",cex.main=1)
plot(lenergia2,main="Serie energía con Transformación BoxCox",cex.main=1)
```

## Estimación de la tendencia

Como se observa en la gráfica de la serie de tiempo no es necesario realizar una estimación de la tendencia para continuar con el análisis descriptivo, sin embargo, se hace una estimación preliminar usando varios métodos, con el fin de comprobar que la serie sin tendencia no varía mucho.

### Tendencia lineal

```{r}
# Creación del objeto tibble
energia_1=energia %>% map_df(rev)
Fechas=as.Date(energia_1$fecha)
energia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)

# Creación objeto tssible a partir del objeto tibble
df_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)
tbl_energia=tibble(df_energia)
tbl_energia_format_fecha=tbl_energia
tsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)
```

En la siguiente salida se presenta el ajuste de una regresión lineal para estimar la tendencia. El $R^2$ indíca qué tan bien se ajusta la recta a los datos, en este caso tiene un valor de $0.058$, por lo que sugiere que no hay tendencia lineal.

```{r}
# Análisis de tendencia con regresion simple
summary(fit_e<-lm(energia2~time(energia2),na.action=NULL))
```

En la @fig-serietiempoenergiareglineal se presenta la serie de tiempo de la energía con la estimación lineal de la tendencia.

```{r}
#| label: fig-serietiempoenergiareglineal
#| fig-cap: >
#|    Gráfico de la serie de tiempo de la energía con la estimación lineal de la tendencia.

plot(energia2, main="Serie de tiempo de la energía diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energía consumida",
     cex.lab=0.4)
abline(fit_e,col="darkcyan",lwd=2)
```

Posteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la @fig-serietiempoenergiasintendreglineal .

```{r}
#| label: fig-serietiempoenergiasintendreglineal
#| fig-cap: >
#|    Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal.

# Eliminación de la tendencia con la predicción la recta
ElimiTendenerg<-energia2-predict(fit_e)
plot(ElimiTendenerg,main="Serie energía sin tendencia",
     cex.main=1.3,
     xlab="Tiempo",
     ylab="Consumo de energía",
     cex.lab=0.4)
```

### Tendencia con promedios móviles

En la @fig-serietiempoenergiaprommovil , se muestra un ajuste de la tendencia con promedios móviles, como se puede ver, aparentemente hay una sobrestimación de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.

```{r}
#| label: fig-serietiempoenergiaprommovil
#| fig-cap: >
#|    Gráfico de la serie de tiempo de la energía sin tendencia estimada con promedios móviles.

# Descomposición filtro de promedios móviles
energia_decompo=decompose(energia2)
plot(energia_decompo)
```

### Tendencia con diferenciación

En la @fig-serietiempoenergiadiff se presentan los gráficos de las series sin tendencia, estimada con regresión lineal y con diferenciación respectivamente, se puede notar que la serie sin tendencia estimada con diferenciación impide ver los ciclos que se ven en la serie original.

```{r}
#| label: fig-serietiempoenergiadiff
#| fig-cap: >
#|    Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal y diferenciación.

tsibble_energia<-as_tsibble(energia2)
par(mar = c(2,2,2,2))
par(mfrow=c(2,1))

plot(resid(fit_e), type="l", main="Sin tendencia lineal") 
plot(diff(energia2), type="l", main="Primera Diferencia") 
```

### Comparación de los ACF

En la @fig-serietiempoenergiaacf se puede notar un descenso rápido hacia 0 para las series original y sin tendencia estimada con regresión lineal, mientras que para la serie sin tendencia estimada con diferenciación, se puede apreciar mejor el ciclo estacional de aproximadamente 7 días.

```{r}
#| label: fig-serietiempoenergiaacf
#| fig-cap: >
#|    Gráficos de autocorrelación para la serie original, sin tendencia estimada con regresión lineal y con la primera diferencia.

# Gráficos de los ACF
par(mar = c(3,2,3,2))
par(mfrow=c(3,1))
acf(energia2, 60, main="ACF energia")
acf(resid(fit_e), 60, main="ACF Sin tendencia") 
acf(diff(energia2), 60, main="ACF Primera Diferencia")
```

Si bien se estima la tendencia con diferentes métodos, se decide trabajar con la serie sin tendencia líneal.

## Gráficas de retardos e índice AMI

```{r}
par(mar = c(3, 2, 3, 2))
astsa::lag1.plot(ElimiTendenerg, 7,corr=F)
```
```{r}
tseriesChaos::mutual(ElimiTendenerg, partitions = 50, lag.max = 10, plot=TRUE) # AMI serie sin tendencia lineal
```

Es posible ver que el primer rezago reduce el estado de incertidumbre para la observación en el tiempo $t$.

## Estimación de la estacionalidad

### Detección de estacionalidad

```{r}
#| warning: false
lineal_1<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
lineal_1<-as.data.frame(lineal_1)
names(lineal_1)<-c("Energia","fecha")

lineal_1$Energia<-as.numeric(lineal_1$Energia)
lineal_1$fecha<-as.Date(lineal_1$fecha)

df_lineal=data.frame(Energia=lineal_1$Energia,fecha=lineal_1$fecha)
tbl_lineal=tibble(df_lineal)
tbl_lineal_format_fecha=tbl_lineal
tsbl_lineal=as_tsibble(tbl_lineal_format_fecha,index=fecha)
```

En la @fig-serietiempoenergiasubseriediar se presenta el gráfico de subseries diarias para la serie original, se puede ver que hay estacionalidad ya que el valor medio del día domingo por ejemplo, es menor al del resto de días.

```{r}
#| label: fig-serietiempoenergiasubseriediar
#| fig-cap: >
#|    Gráfica de subseries diarias.

# Gráfica de subseries semanal con datos originales
gg_subseries(tsbl_lineal,y=Energia,period=7)
```

En la @fig-serietiempoenergiasubseriean se presenta el gráfico de subseries mensuales para la serie original, se puede ver que no hay ciclos estacionales mensuales, ya que todos tienen la misma media. Sin embargo, esto puede deberse a la presencia de la múlriple estacionalidad.

```{r}
#| label: fig-serietiempoenergiasubseriean
#| fig-cap: >
#|    Gráfica de subseries anuales.

# Gráfica de subseries anual con datos originales
gg_subseries(tsbl_lineal,y=Energia,period=12)
```


```{r}
#| warning: false
energia_df<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_df<-as.data.frame(energia_df)
names(energia_df)<-c("Energia","Fecha")

energia_df$Fecha<-as.Date(energia_df$Fecha)
energia_df$time = as.POSIXct(energia_df$Fecha, "%Y-%m-%d")
energia_df$weekday <- wday(energia_df$time, label = TRUE, abbr = TRUE)
energia_df$month <- factor(month.abb[month(energia_df$time)], levels =   month.abb)

# Agrupamos por mes y día
energia_df$Energia<-as.numeric(energia_df$Energia)
energia_mensual <- energia_df %>%
  dplyr::filter(weekday == "dom\\." | weekday == "mar\\." ) %>% # martes se parece al comportamiento de lunes-viernes, domingo se parece a sabado
  dplyr::group_by(weekday, month) %>%
  dplyr::summarise(mean = mean(Energia, na.rm = TRUE),
                   sd = sd(Energia, na.rm = TRUE))

# Grafico consumo (diferenciado) de energia mensual por dia
plot_ly(data = energia_mensual, x = ~ month, y = ~ mean, type =
          "bar",color = ~ weekday) %>%
  layout(title = "Promedio diario de energía por día de la semana",
         yaxis = list(title = "Media"),
         xaxis = list(title = "Mes"))

```


### Periodograma

En la @fig-periodlinealenerg se presenta el periodograma para la serie sin tendencia lineal, el valor del periodo donde se maximiza el periodograma nuevamente es $182.86$, es decir, aproximadamente, el ciclo es de medio año.

```{r}
#| label: fig-periodlinealenerg
#| fig-cap: >
#|    Periodograma para la serie sin tendencia lineal.

# Periodograma sin tendencia lineal
spectrum(as.numeric(ElimiTendenerg),log='no')

PeriodogramaEnergia2_lineal=spectrum(as.numeric(ElimiTendenerg),log='no')
ubicacionlogenergia=which.max(PeriodogramaEnergia2_lineal$spec)

sprintf("El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s",PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])
```

#### Para la serie sin tendencia usando diferenciación

En la @fig-perioddiffenerg se presenta el periodograma para la serie sin tendencia estimada usando diferenciación, el valor del periodo donde se maximiza el periodograma es $3.5$, es decir, aproximadamente, el ciclo es de tres días.

```{r}
#| label: fig-perioddiffenerg
#| fig-cap: >
#|    Periodograma para la serie sin tendencia usando diferenciación.

# Periodograma diferenciación
spectrum(as.numeric(diff(energia2)),log='no')

PeriodogramaEnergia2_dif=spectrum(as.numeric(diff(energia2)),log='no')
ubicacionlogenergia=which.max(PeriodogramaEnergia2_dif$spec)

sprintf("El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s",PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])
```

### Estimación

Ahora procederemos a estimar el ciclo estacional que se observa en esta serie de tiempo, es importante resaltar que con ayuda de los graficos exploratorios y el periodograma se observo que el periodo de la componente estacional es $s=12$, por lo tanto utilizaremos en primer lugar componentes de fourier, esto teniendo en cuenta que se aprecia que la componente estacional sigue un comportamiento deterministico y posiblemente sinosoidal. Teniendo lo anterior en cuenta el modelo viene dado por: $$\begin{align*} x_t&= ∑_{i=1}^k a_icos(k𝜔t)+b_isen(k𝜔t) + w_t \\ \end{align*}$$ Donde $k$ corresponderá al orden de la expansión en series de Fourier y los coeficientes $a_i$ y $b_i$ con $i=1,...,k$ serán estimados a través del método de mínimos cuadrados. El cálculo de esta componente se muestra a continuación considerando un orden $k=3$.


```{r}
# Frecuencia angular w=2*pi/s
frec_ang=(2*pi/182)
frec_ang2=(2*pi/7)

energia_copia<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_copia<-as.data.frame(energia_copia)
names(energia_copia)<-c("Energia","fecha")

energia_copia$fecha<-as.Date(energia_copia$fecha)

#Fourier k=1 
energia_copia$sin = sin(c(1:5054)*(1*frec_ang))
energia_copia$cos = cos(c(1:5054)*(1*frec_ang))

#Fourier k=2 
energia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))
energia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))

#Fourier k=3 
energia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))
energia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))


#Fourier k=1 
energia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))
energia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))

#Fourier k=2 
energia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))
energia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))

#Fourier k=3 
energia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))
energia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))

linmodel_ciclo<-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)

results_ciclo=linmodel_ciclo$fitted.values
results_ciclo<-as.data.frame(results_ciclo)
results_ciclo_ts<-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)

plot(ElimiTendenerg, main="Serie de tiempo de la energía diaria de una empresa estadounidense",
     cex.main=1.3,
     xlab="Tiempo ",
     ylab="Energía consumida",
     cex.lab=0.4)
lines(results_ciclo_ts,col="red")

plot(ElimiTendenerg, main="Serie de tiempo de la energía diaria de una empresa estadounidense",
     cex.main=1.3,
     xlab="Tiempo ",
     ylab="Energía consumida",
     cex.lab=0.4,
     xlim=c(2004,2007))
lines(results_ciclo_ts,col="red",xlim=c(2004,2007))
```

En la @fig-energestacionalidad se presenta la serie original con la estimación de la componente estacional via componentes de Fourier y la serie sin estacionalidad. Se puede notar que las componentes de Fourier logran captar bien es cíclo estacional que tiene la serie. Se toma una componente de Fourier, ya que no hay una diferencia visible al utilizar 2 y 3.

```{r}
#| label: fig-energestacionalidad
#| fig-cap: >
#|    Serie original con estamación de la componente estacional y serie sin estacionalidad.

energia_estacionarios<-ElimiTendenerg-results_ciclo_ts
saveRDS(energia_estacionarios, file="energia_estacionarios.RDS")
plot(ElimiTendenerg-results_ciclo_ts)
plot(ElimiTendenerg-results_ciclo_ts,xlim=c(2004,2007))
```


A continuación, presentaremos el modelo de árboles y el modelo de redes neuronales multicapa paraa esta serie de tiempo, disponible [aquí](https://github.com/Juls5802/Series_de_tiempo/blob/main/Energia.ipynb).

# Ajuste de modelos para serie de Energía

Como vimos en la sección anterior. Para la serie de energía no fue necesario estabilizar la varianza, sin embargo, esta presenta tanto tendencia como multiple estacionalidad ($7$ y $365.25$)

Una vez realizado el análisis descriptivo de la serie de energía, se da inicio al modelamiento de la misma. Este se hará por medio de 3 modelos:

-   Suavizamiento exponencial
-   Modelo ARMA con series de Fourier

Estos modelos serán contrastados con base en su capacidad predictiva para seleccionar el mejor y realizar prediciones con él acerca del consumo diario de energia de la empresa PJM para fechas poseriores al año 2018.

## Suavizamiento Exponencial

##### Carga de la base de datos

```{r}
# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
```

```{r}
# Creación del objeto msts indicando las dos estacionalidades
ly <- msts(energia$Energia,start=c(2004,10,01), seasonal.periods=c(7,365.25))

#HW_ly=stats::HoltWinters(ly,seasonal="additive") # parece que sí funciona

# Predicciones
#forecast::forecast(HW_ly,h=7,level =0.95)
#plot(forecast::forecast(HW_ly,h=7,level =0.95))
```

#### Separación datos de entrenamiento y prueba

Se hizo una división de los datos originales, el $85\%$ para datos de entrenamiento y el $15\%$ restante para datoos de prueba.

```{r}
# Separar train y test

h=1 # Haremos predicciones 1-paso hacia delante

# Datos entrenamiento
ntrain=trunc(length(ly)*0.85) # 4295 datos
train=window(ly,end=time(ly)[ntrain])

# Datos prueba
test=window(ly,start=time(ly)[ntrain]+1/365.25)
ntest=length(test) # 729 datos

# fchstepahe: Vector para guardar las predicciones h-pasos adelante
fchstepahe=matrix(0,nrow=ntest,ncol=h) 

# verval: Vector con los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos
verval=test[1:ntest]
```

#### Ajuste del modelo

En el modelo por medio de suavizamiento exponencial también se considera una descomposición de la serie de forma aditiva. Las componentes de tenendecia y la estacionalidad se estiman por medio de una estadística EWMA (promedio movil ponderado exponencialmente), dándole más peso a las observaciones más cercanas en cada tiempo.

Además, para este caso, se descompone la componente de tendencia en nivel y pendiente, y se estima un parámetro de la componente estacional. Las estimaciones se hallan de la siguiente manera:

$$\begin{align*}
\text{Componente de nivel: } & a_t=α(x_t-S_{t-p})+(1−α)(a_{t−1}+b_{t−1})\\
\text{Componente de pendiente: } & b_t=β(a_t−a_{t−1})+(1−β)b_{t−1} \\
\text{Componente estacional: } & S_t=\gamma(x_t−a_t)+(1−γ)S_{t−p} \\
\end{align*}$$

Para encontrar los parámetros de suavizamiento $\alpha$, $\beta$ y $\gamma$ usamos una grilla con valores desde $0.001$ hasta $0.999$ de a $0.1$ para cada parámetro.

```{r}
#| eval: false
require(utils)

# Propuestas para cada parámetro
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)

# Creación de la grilla
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma)

# Matriz para almacenar los errores
errores<-matrix(NA, nrow=1000,ncol=3) 

# Búsqueda de alpha, beta y gamma con rolling, queremos que minimice ECM
for(i in 1:1000){
  ourCallETS <- "forecast::forecast(stats::HoltWinters(x=data,alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3]),h=h,level=95)"
  ourValueETS <- c("mean","lower","upper")
  origins=ntest   # Número de rolling windows
  Valoresretornados1 <- ro(ly, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE)
  t(Valoresretornados1$holdout) # Permiten verificar los verdaderos valores h-pasos adelante. 
  t(Valoresretornados1$mean)
  errores[i,]<-sqrt(apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE)) # Se calcula la raíz del error cuadrático medio de predicción
}

# Error medio absoluto escalado
errores<-na.omit(errores) 
min(errores[,1]) # RECM= 47201.82
which(errores[,1] == min(errores[,1])) # 885
grilla_suav[885,] # alpha=0.701, beta=0.701, gamma=0.501
```

```{r}
#| echo: false

# Para verificar que sí da ese ECM
for(i in 1:(ntest)){
  x=window(ly,end=time(ly)[ntrain]+(i-1)/365.25)
  refit=stats::HoltWinters(x,seasonal="additive",alpha=0.701,beta=0.701,gamma=0.501) # Ponemos los parametros de la grilla
  fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
errores_pred = verval-fchstepahe # Verdadero en test - Pronóstico test
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)
RECM=sqrt(ECM)
RECM # 47201.82
```

De modo que el modelo final para suavizamiento exponencial es

$$\begin{align*}
\text{Componente de nivel: } & a_t=0.701(x_t-S_{t-p})+(1−0.701)(a_{t−1}+b_{t−1})\\
\text{Componente de pendiente: } & b_t=0.701(a_t−a_{t−1})+(1−0.701)b_{t−1} \\
\text{Componente estacional: } & S_t=0.7501(x_t−a_t)+(1−0.501)S_{t−p} \\
\end{align*}$$

#### Evaluar los supuestos

Aunque en suavizamiento exponencial no se hacen supuestos sobre los residuales, aún así hicimos las pruebas para ver si los residuales tenían un comportamiento similar a ruido blanco.

```{r}
# Verificación de supuestos
HW_train_grilla=stats::HoltWinters(train,seasonal="additive",alpha=0.701,beta=0.701,gamma=0.501) # con los parámetros que dieron mejor en la grilla

# Residuales
res <- ly-HW_train_grilla$fitted[,1]
plot(res)
```

###### No autocorrelación

Luego de ser modelados con el suavizamiento exponencial, parece que aún queda correlación por explicar

```{r}
# ACF
acf(as.numeric(res)) # No deberían estar fuera de las bandas
#acf(res^2)
```

###### No autocorrelación parcial

```{r}
# PACF
pacf(as.numeric(res)) # No deberían estar fuera de las bandas
```

###### Test de normalidad

Parece que no hay normalidad en los residuales

```{r}
# Test de normalidad
## NO queremos rechazar H0 pero pues no es tan grave
tseries::jarque.bera.test(res) # Dice que no son normales
```

###### Test de autocorrelación

Luego de ser modelados con el suavizamiento exponencial, parece que los residuales están correlacionados

```{r}
# Test de autocorrelacion 
## No quieremos rechazar H0
Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2) # No puedo Rechazar la hipótesis de no autocorrelación!
```

###### Estabilización de la varianza

CREO QUE ESTO ES MEJOR NO PONERLO PQ NO SÉ SI SIRVA PARA SUAVIZAMIENTO

```{r}
# Estadisticas CUSUM
## Mide la estabilidad en los parámetros del modelo
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")

# Estadísticas CUSUMSQ
## Mide la estabilidad en la varianza del modelo
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                                           
lines(LQI,type="S",col="red")
```

#### Predicciones sobre datos de prueba

```{r}
verval_ts<-ts(verval,start=time(ly)[ntrain]+1/365.25,frequency=365.25)
fchstepahe_ts<-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)

plot(verval_ts, col = "blue", ylab = "Energía", xlab = "Tiempo")
lines(fchstepahe_ts, col = "red")
legend("topright", legend = c("Reales", "Predicciones"), col = c("blue", "red"), lty = 1)
```

## Proceso ARMA

#### Carga de la base de datos

Para ajustar un modelo de la familia *ARMA(p,q)* es necesario que los datos sean estacionarios, por lo tanto, usamos los datos que resultan luego de eliminar la tendencia línealmente y eliminar la doble estacionalidad que fue modelada usando 6 componentes de Fourier (3 para $s=7$ y 3 para $s=182$)

```{r}
# Datos estacionales
y<-readRDS("energia_estacionarios.RDS") # datos estacionarios
plot(y)
plot(y,xlim=c(2004,2006))
```

Comprobamos que son estacionarios observando la subserie semanal y la subserie mensual

```{r}
# Preliminares
est_1<-cbind(as.matrix(y),as.character(energia$fecha))
est_1<-as.data.frame(est_1)
names(est_1)<-c("Energia","fecha")

est_1$Energia<-as.numeric(est_1$Energia)
est_1$fecha<-as.Date(est_1$fecha)

df_est=data.frame(Energia=est_1$Energia,fecha=est_1$fecha)
tbl_est=tibble(df_est)
tbl_est_format_fecha=tbl_est
tsbl_est=as_tsibble(tbl_est_format_fecha,index=fecha)

# Subserie semanal
gg_subseries(tsbl_est,y=Energia,period=7)

# Subserie mensual
gg_subseries(tsbl_est,y=Energia,period=12)
```

#### Búsqueda de los hiperparámetros *p* y *q*

La búsqueda de los hiperparámetros *p* y *q* se hace vía ACF y PACF

```{r}
# Búsqueda de p,q vía acf y pacf

# Búsqueda de q
acf(as.numeric(y)) # Parece que q es gigante
#acf(as.numeric(y),ci.type='ma') # En efecto, q es grande

# Búsqueda de p
pacf(as.numeric(y)) # p máximo 3, posiblemente 5 o 6
```

Luego de observar los gráficos, vemos que es posible que $p=6$ o menos, y $q$ debe ser grandísimo, por razones prácticas postulamos inicialmente $q=20$, es razonable postular un modelo *AR(6)* y refinarlo, así como también un modelo mixto *ARMA(6,20)* y refinarlo. No es nada razonable pensar en un $MA(q)$ puro por lo que vemos que el ACF decae excesivamente lento.

```{r}
#| echo: false
# Propuesta modelo AR
# Intentamos AR(6) y de ahí para abajo pero F
#modelo.propuesto1=forecast::Arima(y,order=c(3,0,0),fixed=c(NA,NA,NA,0))
#modelo.propuesto1
#lmtest::coeftest(modelo.propuesto1) # todos son significativos menos el 4 y 5
#AIC(modelo.propuesto1)
#BIC(modelo.propuesto1)

# Validacion de supuestos AR
#res <- modelo.propuesto1$residuals
#plot(res)

#acf(res) # no debería haber uno por fuera de las bandas
#acf(res^2) # no debería haber uno por fuera de las bandas pq sino hay una posible relación cuadrática
#pacf(res) # no debrían estar fueraa de las bandas pq si no hay algo que no capta el modelo
#Test de normalidad (no quiero rechazar H0 pero pues no es tan grave)
#tseries::jarque.bera.test(res) # dice que no son normales
#Test de autocorrelacion (no quiero rechazar H0)
#Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2)#No puedo Rechazar la hipótesis de no autocorrelación!


###Estadisticas CUSUM
#cum=cumsum(res)/sd(res)
#N=length(res)
#cumq=cumsum(res^2)/sum(res^2)
#Af=0.948 ###Cuantil del 95% para la estad?stica cusum
#co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
#LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
#LI=-LS
#LQS=co+(1:length(res))/N
#LQI=-co+(1:length(res))/N
#plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
#lines(LS,type="S",col="red")
#lines(LI,type="S",col="red")
#CUSUMSQ
#plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
#lines(LQS,type="S",col="red")                                           
#lines(LQI,type="S",col="red")
```

#### Ajuste del modelo ARMA

Inicialmente se ajustó un modelo *AR(6)* y se refinó, sin embargo no se encontró un modelo autoregresivo puro que cumpliera los supuestos. Luego de una ardua búsqueda, finalmente encontramos un modelo mixto que cumpliera los supuestos, este es *ARMA(5,8)* que también fue refinado, de modo que el modelo final es:

$$X_t=\phi_1 X_{t-1}+\phi_2 X_{t-2}+\phi_3 X_{t-3}+Z_t+\theta_1 Z_{t-1}+\theta_2 Z_{t-2}+\theta_3 Z_{t-3}+\theta_4 Z_{t-4}+\theta_6 Z_{t-6}$$

```{r}
# Propuesta modelo ARMA
modelo.propuesto2=forecast::Arima(y,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)) # ARMA(5,8)
lmtest::coeftest(modelo.propuesto2)
```

#### Evaluar los supuestos

Para los modelos de la familia *ARMA* sí se hacen supuestos sobre los residuales que deben comportarse como ruido blanco. Por lo tanto, es necesario validar los supuestos

```{r}
# Verificación de supuestos ARMA
res <- modelo.propuesto2$residuals
plot(res)
```

###### No autocorrelación

En general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.

```{r}
# ACF
acf(as.numeric(res)) # No deberían estar fuera de las bandas
# acf(as.numeric(res^2))
```

###### No autocorrelación parcial

En general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.

```{r}
# PACF
pacf(as.numeric(res)) # No deberían estar fuera de las bandas
```

##### Test de normalidad

Parece ser que los datos NO son normales.

```{r}
#Test de normalidad 
## No queremos rechazar H0 pero pues no es tan grave
tseries::jarque.bera.test(res)
```

##### Test de autocorrelación

Con un $p-value=$ no hay suficiente evidencia estadística para rechazar la hipóstesis nula, es decir, los residuales NO están correlacionados.

```{r}
#Test de autocorrelacion 
## No queremos rechazar H0 pq es la hipótesis de no autocorrelación
Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2)
```

##### Estabilización de la varianza

Parece que tanto los parámetros como la varianza están "estables".

```{r}
# Estadisticas CUSUM
## Mide la estabilidad en los parámetros del modelo
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")

# Estadísticas CUSUMSQ
## Mide la estabilidad en la varianza del modelo
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                                           
lines(LQI,type="S",col="red")
```

##### Rolling

Una vez verificados los supuestos, se procede a evaluar la capacidad predictiva del modelo mixto. Para ello utilizamos rolling.

```{r}
#| echo: false
# Tendencia

# Creación del objeto tibble
energia_1=energia %>% map_df(rev)
Fechas=as.Date(energia_1$fecha)
energia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)

# Creación objeto tssible a partir del objeto tibble
df_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)
tbl_energia=tibble(df_energia)
tbl_energia_format_fecha=tbl_energia
tsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)

# Regresion lineal simple 
fit_e<-lm(energia2~time(energia2),na.action=NULL)

# Serie sin tendencia
ElimiTendenerg<-energia2-predict(fit_e)
```

```{r}
#| echo: false
# Estacionalidad
energia_copia<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_copia<-as.data.frame(energia_copia)
names(energia_copia)<-c("Energia","fecha")

energia_copia$fecha<-as.Date(energia_copia$fecha)

frec_ang=(2*pi/182) 
frec_ang2=(2*pi/7)

# Para s=182
#Fourier k=1 
energia_copia$sin = sin(c(1:5054)*(1*frec_ang))
energia_copia$cos = cos(c(1:5054)*(1*frec_ang))

#Fourier k=2 
energia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))
energia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))

#Fourier k=3 
energia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))
energia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))

# Para s=7
#Fourier k=1 
energia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))
energia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))

#Fourier k=2 
energia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))
energia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))

#Fourier k=3 
energia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))
energia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))

linmodel_ciclo<-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)

results_ciclo=linmodel_ciclo$fitted.values
results_ciclo<-as.data.frame(results_ciclo)
results_ciclo_ts<-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)
```

```{r}
#| echo: false
# Rolling
#fcmat=matrix(0,nrow=ntest,ncol=h)
#for(i in 1:ntest){
#  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)
#  refit=Arima(x,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)#,method = c("CSS-ML"))
#  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pronósticos #para datos estacionarios
#}
```

```{r}
#| warning: false
# Rolling corregido
fcmat=matrix(0,nrow=ntest,ncol=h)
for(i in 1:ntest){
  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)
  refit=Arima(x,model=modelo.propuesto2)
  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pronósticos para datos estacionarios
}
```

```{r}
#| echo: false
# Esto es para no estar leyendo ese rolling todo el tiempo
#saveRDS(fcmat, file="pron_est.RDS")
fcmat<-readRDS("pron_est.RDS")
```

```{r}
# Para volver a la escala original
estacionalidad<-as.vector(results_ciclo_ts)
tendencia<-as.vector(predict(fit_e))
fchstepahe<-(fcmat+estacionalidad[4296:5054])+tendencia[4296:5054] # primero sumamos la estacionalidad y luego la tendencia

errores_pred = verval-fchstepahe 
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)
RECM=sqrt(ECM)
RECM # 22840.1
```

#### Predicciones sobre datos de prueba

```{r}
fchstepahe_ts<-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)

plot(verval_ts, col = "blue", ylab = "Energía", xlab = "Tiempo")
lines(fchstepahe_ts, col = "red")
legend("topright", legend = c("Reales", "Predicciones"), col = c("blue", "red"), lty = 1)
```

## Proceso ARIMA

Para ajustar un modelo ARIMA (aunque no es lo más adecuado dado que la serie presenta componente estacional), primero se debe comprobar si la serie de tiempo presenta una raíz unitaria. Teniendo en cuenta que, para la prueba de Dicker Fuller, si el $p-valor$ es menor que un nivel de significancia $\alpha$ se rechaza la hipotesis nula de que la serie de tiempo presenta una raíz unitaria, se tiene lo siguiente.

```{r}
stats::ar(energia2) # Selecciona un modelo AR usando el criterio de Akaike, sugiere tomar lags=36
tseries::adf.test(energia2,k=36) # Prueba Dicker Fuller: No hay raíz unitaria
summary(ur.df(energia2,type="trend",lags = 36))
```

Como se puede ver, en ambos casos las pruebas muestran que la serie no presenta raíces unitarias, por lo que ajustar este modelo no es adecuado.

## Proceso SARIMA

Dado que la serie presenta multiple estacionalidad, no es posible ajustar un modelo de la familia SARIMA.
