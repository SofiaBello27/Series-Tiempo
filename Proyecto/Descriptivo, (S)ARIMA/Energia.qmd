# An√°lisis del consumo de energ√≠a de la empresa PJM

## An√°lisis del consumo de energ√≠a de la empresa PJM

La empresa PJM es una organizaci√≥n de transmisi√≥n regional que coordina el movimiento de electricidad mayorista en la totalidad, o parte, de 13 estados y el Distrito de Columbia.

El an√°lisis del consumo de energ√≠a es esencial para mejorar la eficiencia operativa, reducir costos, cumplir con regulaciones y promover la sostenibilidad, por lo cual, este proyecto analiza la serie de tiempo con el fin de encontrar variaciones en el consumo de energ√≠a de los 13 estados y el Distrito de Columbia a lo largo del tiempo, as√≠ como tambi√©n descubrir posibles patrones.

A continuaci√≥n se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la @fig-serietiempoenergia .

```{r}
#| label: fig-serietiempoenergia
#| fig-cap: >
#|    Gr√°fico de la serie de tiempo de la energ√≠a.

# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]

# Gr√°fico de la serie de tiempo
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
plot(energia2, main="Serie de tiempo de la energ√≠a diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energ√≠a consumida",
     cex.lab=0.4)

```

# An√°lisis descriptivo
```{r}
#| warning: false
#| message: false
# Librer√≠as necesarias
library(TSstudio)
library(readxl)
library(dplyr)
library(lubridate)
library(astsa)
library(feasts)
library(fable)
library(timetk)
library(tsibble)
library(zoo)
library(xts)
library(readxl)
library(tidyverse)
library(nonlinearTseries)
library(tseriesChaos) 
library(forecast)
library(plotly)
library(dplyr)
library(parsnip)
library(rsample)
library(timetk)
library(modeltime)
library(tsibble)
library(tidymodels)
library(greybox)
library(TSA)
library(urca)
library(lmtest)
library(uroot)
library(fUnitRoots)
library(sarima)
library(TSA)
require("PolynomF")
require("forecast")
```

```{r}
#| warning: false

# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
```

Seg√∫n lo observado en la serie de tiempo (@fig-serieenergia2), visualmente se tiene:

```{r}
#| label: fig-serieenergia2
#| fig-cap: >
#|    Gr√°fico de la verosimilitud en funci√≥n del hiperpar√°metro lambda.

# Gr√°fico de la serie de tiempo
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
plot(energia2, main="Serie de tiempo de la energ√≠a diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energ√≠a consumida",
     cex.lab=0.4)
```

-   **Heterocedasticidad marginal:** Se puede observar que la varianza de cada instante en la serie es casi la misma. Al parecer no es necesario estabilizar la varianza.
-   **Tendencia:** A simple vista se observa que, a medida que pasa el tiempo la serie oscila al rededor del mismo valor, por lo tanto, no es necesario estimar la tendencia.
-   **Componente estacional:** Se observan algunos patrones que se repiten con cierta periodicidad, lo cual hace que sea necesario observar la posible presencia de componente estacional y posteriormente estimarla.

## Estabilizaci√≥n de la varianza marginal

Como se observa en la gr√°fica de la serie de tiempo no es necesario realizar una estabilizaci√≥n de la varianza para continuar con el an√°lisis descriptivo, sin embargo, para comprobar esto, se hace una transformaci√≥n de Box-cox para ver que tanto se estabiliza la varianza. En la @fig-boxcox1energia se observa que se sugiere una transformaci√≥n dado que 1 no est√° contenido en el intervalo.

```{r}
#| label: fig-boxcox1energia
#| fig-cap: >
#|    Gr√°fico de la verosimilitud en funci√≥n del hiperpar√°metro lambda.
MASS::boxcox(lm(energia2 ~ 1),seq(-5, 5, length = 50))
abline(v = 1, col = "red", lty = 2)
```

En la siguiente salida se puede ver que el $\lambda$ sugerido es $-0.25$, como es un n√∫mero negativo, se procede a hacer la transformaci√≥n Box-Cox usando logaritmo natural.

```{r}
forecast::BoxCox.lambda(energia2, method ="loglik",lower = -1, upper = 3)
```

En la @fig-boxcox1lenergia a continuaci√≥n se muestra que la serie en escala logar√≠tmica nuevamente no tiene la varianza estabilizada, dado que no se contiene al 1.

```{r}
#| label: fig-boxcox1lenergia
#| fig-cap: >
#|    Gr√°fico de la verosimilitud para la serie en escala logar√≠tmica, en funci√≥n del hiperpar√°metro lambda.
lenergia2=log(energia2)
MASS::boxcox(lm(lenergia2 ~ 1),seq(-5, 5, length =  50))
abline(v = 1, col = "red", lty = 2)
```

Adem√°s, se puede notar en la @fig-sinconboxcoxenerg , que no hay una diferencia significativa entre la serie transformada y no transformada. Por lo que el an√°lisis descriptivo se contin√∫a usando los datos originales.

```{r}
#| label: fig-sinconboxcoxenerg
#| fig-cap: >
#|    Serie original y serie con transformaci√≥n logar√≠tmica.
par(mar = c(1,1,1,1))
par(mfrow=c(2,1),mar=c(3,3,3,3))
plot(energia2,main="Serie energ√≠a sin Transformar",cex.main=1)
plot(lenergia2,main="Serie energ√≠a con Transformaci√≥n BoxCox",cex.main=1)
```

## Estimaci√≥n de la tendencia

Como se observa en la gr√°fica de la serie de tiempo no es necesario realizar una estimaci√≥n de la tendencia para continuar con el an√°lisis descriptivo, sin embargo, se hace una estimaci√≥n preliminar usando varios m√©todos, con el fin de comprobar que la serie sin tendencia no var√≠a mucho.

### Tendencia lineal

```{r}
# Creaci√≥n del objeto tibble
energia_1=energia %>% map_df(rev)
Fechas=as.Date(energia_1$fecha)
energia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)

# Creaci√≥n objeto tssible a partir del objeto tibble
df_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)
tbl_energia=tibble(df_energia)
tbl_energia_format_fecha=tbl_energia
tsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)
```

En la siguiente salida se presenta el ajuste de una regresi√≥n lineal para estimar la tendencia. El $R^2$ ind√≠ca qu√© tan bien se ajusta la recta a los datos, en este caso tiene un valor de $0.058$, por lo que sugiere que no hay tendencia lineal.

```{r}
# An√°lisis de tendencia con regresion simple
summary(fit_e<-lm(energia2~time(energia2),na.action=NULL))
```

En la @fig-serietiempoenergiareglineal se presenta la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.

```{r}
#| label: fig-serietiempoenergiareglineal
#| fig-cap: >
#|    Gr√°fico de la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.

plot(energia2, main="Serie de tiempo de la energ√≠a diaria de una empresa estadounidense",
     cex.main=1,
     xlab="Tiempo ",
     ylab="Energ√≠a consumida",
     cex.lab=0.4)
abline(fit_e,col="darkcyan",lwd=2)
```

Posteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la @fig-serietiempoenergiasintendreglineal .

```{r}
#| label: fig-serietiempoenergiasintendreglineal
#| fig-cap: >
#|    Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal.

# Eliminaci√≥n de la tendencia con la predicci√≥n la recta
ElimiTendenerg<-energia2-predict(fit_e)
plot(ElimiTendenerg,main="Serie energ√≠a sin tendencia",
     cex.main=1.3,
     xlab="Tiempo",
     ylab="Consumo de energ√≠a",
     cex.lab=0.4)
```

### Tendencia con promedios m√≥viles

En la @fig-serietiempoenergiaprommovil , se muestra un ajuste de la tendencia con promedios m√≥viles, como se puede ver, aparentemente hay una sobrestimaci√≥n de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.

```{r}
#| label: fig-serietiempoenergiaprommovil
#| fig-cap: >
#|    Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con promedios m√≥viles.

# Descomposici√≥n filtro de promedios m√≥viles
energia_decompo=decompose(energia2)
plot(energia_decompo)
```

### Tendencia con diferenciaci√≥n

En la @fig-serietiempoenergiadiff se presentan los gr√°ficos de las series sin tendencia, estimada con regresi√≥n lineal y con diferenciaci√≥n respectivamente, se puede notar que la serie sin tendencia estimada con diferenciaci√≥n impide ver los ciclos que se ven en la serie original.

```{r}
#| label: fig-serietiempoenergiadiff
#| fig-cap: >
#|    Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal y diferenciaci√≥n.

tsibble_energia<-as_tsibble(energia2)
par(mar = c(2,2,2,2))
par(mfrow=c(2,1))

plot(resid(fit_e), type="l", main="Sin tendencia lineal") 
plot(diff(energia2), type="l", main="Primera Diferencia") 
```

### Comparaci√≥n de los ACF

En la @fig-serietiempoenergiaacf se puede notar un descenso r√°pido hacia 0 para las series original y sin tendencia estimada con regresi√≥n lineal, mientras que para la serie sin tendencia estimada con diferenciaci√≥n, se puede apreciar mejor el ciclo estacional de aproximadamente 7 d√≠as.

```{r}
#| label: fig-serietiempoenergiaacf
#| fig-cap: >
#|    Gr√°ficos de autocorrelaci√≥n para la serie original, sin tendencia estimada con regresi√≥n lineal y con la primera diferencia.

# Gr√°ficos de los ACF
par(mar = c(3,2,3,2))
par(mfrow=c(3,1))
acf(energia2, 60, main="ACF energia")
acf(resid(fit_e), 60, main="ACF Sin tendencia") 
acf(diff(energia2), 60, main="ACF Primera Diferencia")
```

Si bien se estima la tendencia con diferentes m√©todos, se decide trabajar con la serie sin tendencia l√≠neal.

## Gr√°ficas de retardos e √≠ndice AMI

```{r}
par(mar = c(3, 2, 3, 2))
astsa::lag1.plot(ElimiTendenerg, 7,corr=F)
```
```{r}
tseriesChaos::mutual(ElimiTendenerg, partitions = 50, lag.max = 10, plot=TRUE) # AMI serie sin tendencia lineal
```

Es posible ver que el primer rezago reduce el estado de incertidumbre para la observaci√≥n en el tiempo $t$.

## Estimaci√≥n de la estacionalidad

### Detecci√≥n de estacionalidad

```{r}
#| warning: false
lineal_1<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
lineal_1<-as.data.frame(lineal_1)
names(lineal_1)<-c("Energia","fecha")

lineal_1$Energia<-as.numeric(lineal_1$Energia)
lineal_1$fecha<-as.Date(lineal_1$fecha)

df_lineal=data.frame(Energia=lineal_1$Energia,fecha=lineal_1$fecha)
tbl_lineal=tibble(df_lineal)
tbl_lineal_format_fecha=tbl_lineal
tsbl_lineal=as_tsibble(tbl_lineal_format_fecha,index=fecha)
```

En la @fig-serietiempoenergiasubseriediar se presenta el gr√°fico de subseries diarias para la serie original, se puede ver que hay estacionalidad ya que el valor medio del d√≠a domingo por ejemplo, es menor al del resto de d√≠as.

```{r}
#| label: fig-serietiempoenergiasubseriediar
#| fig-cap: >
#|    Gr√°fica de subseries diarias.

# Gr√°fica de subseries semanal con datos originales
gg_subseries(tsbl_lineal,y=Energia,period=7)
```

En la @fig-serietiempoenergiasubseriean se presenta el gr√°fico de subseries mensuales para la serie original, se puede ver que no hay ciclos estacionales mensuales, ya que todos tienen la misma media. Sin embargo, esto puede deberse a la presencia de la m√∫lriple estacionalidad.

```{r}
#| label: fig-serietiempoenergiasubseriean
#| fig-cap: >
#|    Gr√°fica de subseries anuales.

# Gr√°fica de subseries anual con datos originales
gg_subseries(tsbl_lineal,y=Energia,period=12)
```


```{r}
#| warning: false
energia_df<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_df<-as.data.frame(energia_df)
names(energia_df)<-c("Energia","Fecha")

energia_df$Fecha<-as.Date(energia_df$Fecha)
energia_df$time = as.POSIXct(energia_df$Fecha, "%Y-%m-%d")
energia_df$weekday <- wday(energia_df$time, label = TRUE, abbr = TRUE)
energia_df$month <- factor(month.abb[month(energia_df$time)], levels =   month.abb)

# Agrupamos por mes y d√≠a
energia_df$Energia<-as.numeric(energia_df$Energia)
energia_mensual <- energia_df %>%
  dplyr::filter(weekday == "dom\\." | weekday == "mar\\." ) %>% # martes se parece al comportamiento de lunes-viernes, domingo se parece a sabado
  dplyr::group_by(weekday, month) %>%
  dplyr::summarise(mean = mean(Energia, na.rm = TRUE),
                   sd = sd(Energia, na.rm = TRUE))

# Grafico consumo (diferenciado) de energia mensual por dia
plot_ly(data = energia_mensual, x = ~ month, y = ~ mean, type =
          "bar",color = ~ weekday) %>%
  layout(title = "Promedio diario de energ√≠a por d√≠a de la semana",
         yaxis = list(title = "Media"),
         xaxis = list(title = "Mes"))

```


### Periodograma

En la @fig-periodlinealenerg se presenta el periodograma para la serie sin tendencia lineal, el valor del periodo donde se maximiza el periodograma nuevamente es $182.86$, es decir, aproximadamente, el ciclo es de medio a√±o.

```{r}
#| label: fig-periodlinealenerg
#| fig-cap: >
#|    Periodograma para la serie sin tendencia lineal.

# Periodograma sin tendencia lineal
spectrum(as.numeric(ElimiTendenerg),log='no')

PeriodogramaEnergia2_lineal=spectrum(as.numeric(ElimiTendenerg),log='no')
ubicacionlogenergia=which.max(PeriodogramaEnergia2_lineal$spec)

sprintf("El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s",PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])
```

#### Para la serie sin tendencia usando diferenciaci√≥n

En la @fig-perioddiffenerg se presenta el periodograma para la serie sin tendencia estimada usando diferenciaci√≥n, el valor del periodo donde se maximiza el periodograma es $3.5$, es decir, aproximadamente, el ciclo es de tres d√≠as.

```{r}
#| label: fig-perioddiffenerg
#| fig-cap: >
#|    Periodograma para la serie sin tendencia usando diferenciaci√≥n.

# Periodograma diferenciaci√≥n
spectrum(as.numeric(diff(energia2)),log='no')

PeriodogramaEnergia2_dif=spectrum(as.numeric(diff(energia2)),log='no')
ubicacionlogenergia=which.max(PeriodogramaEnergia2_dif$spec)

sprintf("El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s",PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])
```

### Estimaci√≥n

Ahora procederemos a estimar el ciclo estacional que se observa en esta serie de tiempo, es importante resaltar que con ayuda de los graficos exploratorios y el periodograma se observo que el periodo de la componente estacional es $s=12$, por lo tanto utilizaremos en primer lugar componentes de fourier, esto teniendo en cuenta que se aprecia que la componente estacional sigue un comportamiento deterministico y posiblemente sinosoidal. Teniendo lo anterior en cuenta el modelo viene dado por: $$\begin{align*} x_t&= ‚àë_{i=1}^k a_icos(kùúît)+b_isen(kùúît) + w_t \\ \end{align*}$$ Donde $k$ corresponder√° al orden de la expansi√≥n en series de Fourier y los coeficientes $a_i$ y $b_i$ con $i=1,...,k$ ser√°n estimados a trav√©s del m√©todo de m√≠nimos cuadrados. El c√°lculo de esta componente se muestra a continuaci√≥n considerando un orden $k=3$.


```{r}
# Frecuencia angular w=2*pi/s
frec_ang=(2*pi/182)
frec_ang2=(2*pi/7)

energia_copia<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_copia<-as.data.frame(energia_copia)
names(energia_copia)<-c("Energia","fecha")

energia_copia$fecha<-as.Date(energia_copia$fecha)

#Fourier k=1 
energia_copia$sin = sin(c(1:5054)*(1*frec_ang))
energia_copia$cos = cos(c(1:5054)*(1*frec_ang))

#Fourier k=2 
energia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))
energia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))

#Fourier k=3 
energia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))
energia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))


#Fourier k=1 
energia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))
energia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))

#Fourier k=2 
energia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))
energia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))

#Fourier k=3 
energia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))
energia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))

linmodel_ciclo<-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)

results_ciclo=linmodel_ciclo$fitted.values
results_ciclo<-as.data.frame(results_ciclo)
results_ciclo_ts<-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)

plot(ElimiTendenerg, main="Serie de tiempo de la energ√≠a diaria de una empresa estadounidense",
     cex.main=1.3,
     xlab="Tiempo ",
     ylab="Energ√≠a consumida",
     cex.lab=0.4)
lines(results_ciclo_ts,col="red")

plot(ElimiTendenerg, main="Serie de tiempo de la energ√≠a diaria de una empresa estadounidense",
     cex.main=1.3,
     xlab="Tiempo ",
     ylab="Energ√≠a consumida",
     cex.lab=0.4,
     xlim=c(2004,2007))
lines(results_ciclo_ts,col="red",xlim=c(2004,2007))
```

En la @fig-energestacionalidad se presenta la serie original con la estimaci√≥n de la componente estacional via componentes de Fourier y la serie sin estacionalidad. Se puede notar que las componentes de Fourier logran captar bien es c√≠clo estacional que tiene la serie. Se toma una componente de Fourier, ya que no hay una diferencia visible al utilizar 2 y 3.

```{r}
#| label: fig-energestacionalidad
#| fig-cap: >
#|    Serie original con estamaci√≥n de la componente estacional y serie sin estacionalidad.

energia_estacionarios<-ElimiTendenerg-results_ciclo_ts
saveRDS(energia_estacionarios, file="energia_estacionarios.RDS")
plot(ElimiTendenerg-results_ciclo_ts)
plot(ElimiTendenerg-results_ciclo_ts,xlim=c(2004,2007))
```


A continuaci√≥n, presentaremos el modelo de √°rboles y el modelo de redes neuronales multicapa paraa esta serie de tiempo, disponible [aqu√≠](https://github.com/Juls5802/Series_de_tiempo/blob/main/Energia.ipynb).

# Ajuste de modelos para serie de Energ√≠a

Como vimos en la secci√≥n anterior. Para la serie de energ√≠a no fue necesario estabilizar la varianza, sin embargo, esta presenta tanto tendencia como multiple estacionalidad ($7$ y $365.25$)

Una vez realizado el an√°lisis descriptivo de la serie de energ√≠a, se da inicio al modelamiento de la misma. Este se har√° por medio de 3 modelos:

-   Suavizamiento exponencial
-   Modelo ARMA con series de Fourier

Estos modelos ser√°n contrastados con base en su capacidad predictiva para seleccionar el mejor y realizar prediciones con √©l acerca del consumo diario de energia de la empresa PJM para fechas poseriores al a√±o 2018.

## Suavizamiento Exponencial

##### Carga de la base de datos

```{r}
# Carga de la base de datos
AEP_hourly<-read.csv("AEP_hourly.csv")
AEP_hourly$Datetime<-as.POSIXct(AEP_hourly$Datetime, format = "%Y-%m-%d %H:%M:%S")
AEP_hourly$fecha<-as.Date(AEP_hourly$Datetime)

energia <- AEP_hourly %>%
  group_by(fecha) %>%
  summarise(Energia = sum(AEP_MW))
energia<-energia[-5055,]
energia2<-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)
```

```{r}
# Creaci√≥n del objeto msts indicando las dos estacionalidades
ly <- msts(energia$Energia,start=c(2004,10,01), seasonal.periods=c(7,365.25))

#HW_ly=stats::HoltWinters(ly,seasonal="additive") # parece que s√≠ funciona

# Predicciones
#forecast::forecast(HW_ly,h=7,level =0.95)
#plot(forecast::forecast(HW_ly,h=7,level =0.95))
```

#### Separaci√≥n datos de entrenamiento y prueba

Se hizo una divisi√≥n de los datos originales, el $85\%$ para datos de entrenamiento y el $15\%$ restante para datoos de prueba.

```{r}
# Separar train y test

h=1 # Haremos predicciones 1-paso hacia delante

# Datos entrenamiento
ntrain=trunc(length(ly)*0.85) # 4295 datos
train=window(ly,end=time(ly)[ntrain])

# Datos prueba
test=window(ly,start=time(ly)[ntrain]+1/365.25)
ntest=length(test) # 729 datos

# fchstepahe: Vector para guardar las predicciones h-pasos adelante
fchstepahe=matrix(0,nrow=ntest,ncol=h) 

# verval: Vector con los verdaderos valores de la serie en el conjunto de prueba con los que se comparar√°n los pron√≥sticos
verval=test[1:ntest]
```

#### Ajuste del modelo

En el modelo por medio de suavizamiento exponencial tambi√©n se considera una descomposici√≥n de la serie de forma aditiva. Las componentes de tenendecia y la estacionalidad se estiman por medio de una estad√≠stica EWMA (promedio movil ponderado exponencialmente), d√°ndole m√°s peso a las observaciones m√°s cercanas en cada tiempo.

Adem√°s, para este caso, se descompone la componente de tendencia en nivel y pendiente, y se estima un par√°metro de la componente estacional. Las estimaciones se hallan de la siguiente manera:

$$\begin{align*}
\text{Componente de nivel: } & a_t=Œ±(x_t-S_{t-p})+(1‚àíŒ±)(a_{t‚àí1}+b_{t‚àí1})\\
\text{Componente de pendiente: } & b_t=Œ≤(a_t‚àía_{t‚àí1})+(1‚àíŒ≤)b_{t‚àí1} \\
\text{Componente estacional: } & S_t=\gamma(x_t‚àía_t)+(1‚àíŒ≥)S_{t‚àíp} \\
\end{align*}$$

Para encontrar los par√°metros de suavizamiento $\alpha$, $\beta$ y $\gamma$ usamos una grilla con valores desde $0.001$ hasta $0.999$ de a $0.1$ para cada par√°metro.

```{r}
#| eval: false
require(utils)

# Propuestas para cada par√°metro
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)

# Creaci√≥n de la grilla
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma)

# Matriz para almacenar los errores
errores<-matrix(NA, nrow=1000,ncol=3) 

# B√∫squeda de alpha, beta y gamma con rolling, queremos que minimice ECM
for(i in 1:1000){
  ourCallETS <- "forecast::forecast(stats::HoltWinters(x=data,alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3]),h=h,level=95)"
  ourValueETS <- c("mean","lower","upper")
  origins=ntest   # N√∫mero de rolling windows
  Valoresretornados1 <- ro(ly, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE)
  t(Valoresretornados1$holdout) # Permiten verificar los verdaderos valores h-pasos adelante. 
  t(Valoresretornados1$mean)
  errores[i,]<-sqrt(apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE)) # Se calcula la ra√≠z del error cuadr√°tico medio de predicci√≥n
}

# Error medio absoluto escalado
errores<-na.omit(errores) 
min(errores[,1]) # RECM= 47201.82
which(errores[,1] == min(errores[,1])) # 885
grilla_suav[885,] # alpha=0.701, beta=0.701, gamma=0.501
```

```{r}
#| echo: false

# Para verificar que s√≠ da ese ECM
for(i in 1:(ntest)){
  x=window(ly,end=time(ly)[ntrain]+(i-1)/365.25)
  refit=stats::HoltWinters(x,seasonal="additive",alpha=0.701,beta=0.701,gamma=0.501) # Ponemos los parametros de la grilla
  fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
errores_pred = verval-fchstepahe # Verdadero en test - Pron√≥stico test
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)
RECM=sqrt(ECM)
RECM # 47201.82
```

De modo que el modelo final para suavizamiento exponencial es

$$\begin{align*}
\text{Componente de nivel: } & a_t=0.701(x_t-S_{t-p})+(1‚àí0.701)(a_{t‚àí1}+b_{t‚àí1})\\
\text{Componente de pendiente: } & b_t=0.701(a_t‚àía_{t‚àí1})+(1‚àí0.701)b_{t‚àí1} \\
\text{Componente estacional: } & S_t=0.7501(x_t‚àía_t)+(1‚àí0.501)S_{t‚àíp} \\
\end{align*}$$

#### Evaluar los supuestos

Aunque en suavizamiento exponencial no se hacen supuestos sobre los residuales, a√∫n as√≠ hicimos las pruebas para ver si los residuales ten√≠an un comportamiento similar a ruido blanco.

```{r}
# Verificaci√≥n de supuestos
HW_train_grilla=stats::HoltWinters(train,seasonal="additive",alpha=0.701,beta=0.701,gamma=0.501) # con los par√°metros que dieron mejor en la grilla

# Residuales
res <- ly-HW_train_grilla$fitted[,1]
plot(res)
```

###### No autocorrelaci√≥n

Luego de ser modelados con el suavizamiento exponencial, parece que a√∫n queda correlaci√≥n por explicar

```{r}
# ACF
acf(as.numeric(res)) # No deber√≠an estar fuera de las bandas
#acf(res^2)
```

###### No autocorrelaci√≥n parcial

```{r}
# PACF
pacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas
```

###### Test de normalidad

Parece que no hay normalidad en los residuales

```{r}
# Test de normalidad
## NO queremos rechazar H0 pero pues no es tan grave
tseries::jarque.bera.test(res) # Dice que no son normales
```

###### Test de autocorrelaci√≥n

Luego de ser modelados con el suavizamiento exponencial, parece que los residuales est√°n correlacionados

```{r}
# Test de autocorrelacion 
## No quieremos rechazar H0
Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2) # No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!
```

###### Estabilizaci√≥n de la varianza

CREO QUE ESTO ES MEJOR NO PONERLO PQ NO S√â SI SIRVA PARA SUAVIZAMIENTO

```{r}
# Estadisticas CUSUM
## Mide la estabilidad en los par√°metros del modelo
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")

# Estad√≠sticas CUSUMSQ
## Mide la estabilidad en la varianza del modelo
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                                           
lines(LQI,type="S",col="red")
```

#### Predicciones sobre datos de prueba

```{r}
verval_ts<-ts(verval,start=time(ly)[ntrain]+1/365.25,frequency=365.25)
fchstepahe_ts<-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)

plot(verval_ts, col = "blue", ylab = "Energ√≠a", xlab = "Tiempo")
lines(fchstepahe_ts, col = "red")
legend("topright", legend = c("Reales", "Predicciones"), col = c("blue", "red"), lty = 1)
```

## Proceso ARMA

#### Carga de la base de datos

Para ajustar un modelo de la familia *ARMA(p,q)* es necesario que los datos sean estacionarios, por lo tanto, usamos los datos que resultan luego de eliminar la tendencia l√≠nealmente y eliminar la doble estacionalidad que fue modelada usando 6 componentes de Fourier (3 para $s=7$ y 3 para $s=182$)

```{r}
# Datos estacionales
y<-readRDS("energia_estacionarios.RDS") # datos estacionarios
plot(y)
plot(y,xlim=c(2004,2006))
```

Comprobamos que son estacionarios observando la subserie semanal y la subserie mensual

```{r}
# Preliminares
est_1<-cbind(as.matrix(y),as.character(energia$fecha))
est_1<-as.data.frame(est_1)
names(est_1)<-c("Energia","fecha")

est_1$Energia<-as.numeric(est_1$Energia)
est_1$fecha<-as.Date(est_1$fecha)

df_est=data.frame(Energia=est_1$Energia,fecha=est_1$fecha)
tbl_est=tibble(df_est)
tbl_est_format_fecha=tbl_est
tsbl_est=as_tsibble(tbl_est_format_fecha,index=fecha)

# Subserie semanal
gg_subseries(tsbl_est,y=Energia,period=7)

# Subserie mensual
gg_subseries(tsbl_est,y=Energia,period=12)
```

#### B√∫squeda de los hiperpar√°metros *p* y *q*

La b√∫squeda de los hiperpar√°metros *p* y *q* se hace v√≠a ACF y PACF

```{r}
# B√∫squeda de p,q v√≠a acf y pacf

# B√∫squeda de q
acf(as.numeric(y)) # Parece que q es gigante
#acf(as.numeric(y),ci.type='ma') # En efecto, q es grande

# B√∫squeda de p
pacf(as.numeric(y)) # p m√°ximo 3, posiblemente 5 o 6
```

Luego de observar los gr√°ficos, vemos que es posible que $p=6$ o menos, y $q$ debe ser grand√≠simo, por razones pr√°cticas postulamos inicialmente $q=20$, es razonable postular un modelo *AR(6)* y refinarlo, as√≠ como tambi√©n un modelo mixto *ARMA(6,20)* y refinarlo. No es nada razonable pensar en un $MA(q)$ puro por lo que vemos que el ACF decae excesivamente lento.

```{r}
#| echo: false
# Propuesta modelo AR
# Intentamos AR(6) y de ah√≠ para abajo pero F
#modelo.propuesto1=forecast::Arima(y,order=c(3,0,0),fixed=c(NA,NA,NA,0))
#modelo.propuesto1
#lmtest::coeftest(modelo.propuesto1) # todos son significativos menos el 4 y 5
#AIC(modelo.propuesto1)
#BIC(modelo.propuesto1)

# Validacion de supuestos AR
#res <- modelo.propuesto1$residuals
#plot(res)

#acf(res) # no deber√≠a haber uno por fuera de las bandas
#acf(res^2) # no deber√≠a haber uno por fuera de las bandas pq sino hay una posible relaci√≥n cuadr√°tica
#pacf(res) # no debr√≠an estar fueraa de las bandas pq si no hay algo que no capta el modelo
#Test de normalidad (no quiero rechazar H0 pero pues no es tan grave)
#tseries::jarque.bera.test(res) # dice que no son normales
#Test de autocorrelacion (no quiero rechazar H0)
#Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!


###Estadisticas CUSUM
#cum=cumsum(res)/sd(res)
#N=length(res)
#cumq=cumsum(res^2)/sum(res^2)
#Af=0.948 ###Cuantil del 95% para la estad?stica cusum
#co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
#LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
#LI=-LS
#LQS=co+(1:length(res))/N
#LQI=-co+(1:length(res))/N
#plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
#lines(LS,type="S",col="red")
#lines(LI,type="S",col="red")
#CUSUMSQ
#plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
#lines(LQS,type="S",col="red")                                           
#lines(LQI,type="S",col="red")
```

#### Ajuste del modelo ARMA

Inicialmente se ajust√≥ un modelo *AR(6)* y se refin√≥, sin embargo no se encontr√≥ un modelo autoregresivo puro que cumpliera los supuestos. Luego de una ardua b√∫squeda, finalmente encontramos un modelo mixto que cumpliera los supuestos, este es *ARMA(5,8)* que tambi√©n fue refinado, de modo que el modelo final es:

$$X_t=\phi_1 X_{t-1}+\phi_2 X_{t-2}+\phi_3 X_{t-3}+Z_t+\theta_1 Z_{t-1}+\theta_2 Z_{t-2}+\theta_3 Z_{t-3}+\theta_4 Z_{t-4}+\theta_6 Z_{t-6}$$

```{r}
# Propuesta modelo ARMA
modelo.propuesto2=forecast::Arima(y,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)) # ARMA(5,8)
lmtest::coeftest(modelo.propuesto2)
```

#### Evaluar los supuestos

Para los modelos de la familia *ARMA* s√≠ se hacen supuestos sobre los residuales que deben comportarse como ruido blanco. Por lo tanto, es necesario validar los supuestos

```{r}
# Verificaci√≥n de supuestos ARMA
res <- modelo.propuesto2$residuals
plot(res)
```

###### No autocorrelaci√≥n

En general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.

```{r}
# ACF
acf(as.numeric(res)) # No deber√≠an estar fuera de las bandas
# acf(as.numeric(res^2))
```

###### No autocorrelaci√≥n parcial

En general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.

```{r}
# PACF
pacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas
```

##### Test de normalidad

Parece ser que los datos NO son normales.

```{r}
#Test de normalidad 
## No queremos rechazar H0 pero pues no es tan grave
tseries::jarque.bera.test(res)
```

##### Test de autocorrelaci√≥n

Con un $p-value=$ no hay suficiente evidencia estad√≠stica para rechazar la hip√≥stesis nula, es decir, los residuales NO est√°n correlacionados.

```{r}
#Test de autocorrelacion 
## No queremos rechazar H0 pq es la hip√≥tesis de no autocorrelaci√≥n
Box.test(res, lag =20 , type = "Ljung-Box", fitdf = 2)
```

##### Estabilizaci√≥n de la varianza

Parece que tanto los par√°metros como la varianza est√°n "estables".

```{r}
# Estadisticas CUSUM
## Mide la estabilidad en los par√°metros del modelo
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.01717####Valor del cuantil aproximado para cusumsq para n/2
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")

# Estad√≠sticas CUSUMSQ
## Mide la estabilidad en la varianza del modelo
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                                           
lines(LQI,type="S",col="red")
```

##### Rolling

Una vez verificados los supuestos, se procede a evaluar la capacidad predictiva del modelo mixto. Para ello utilizamos rolling.

```{r}
#| echo: false
# Tendencia

# Creaci√≥n del objeto tibble
energia_1=energia %>% map_df(rev)
Fechas=as.Date(energia_1$fecha)
energia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)

# Creaci√≥n objeto tssible a partir del objeto tibble
df_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)
tbl_energia=tibble(df_energia)
tbl_energia_format_fecha=tbl_energia
tsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)

# Regresion lineal simple 
fit_e<-lm(energia2~time(energia2),na.action=NULL)

# Serie sin tendencia
ElimiTendenerg<-energia2-predict(fit_e)
```

```{r}
#| echo: false
# Estacionalidad
energia_copia<-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))
energia_copia<-as.data.frame(energia_copia)
names(energia_copia)<-c("Energia","fecha")

energia_copia$fecha<-as.Date(energia_copia$fecha)

frec_ang=(2*pi/182) 
frec_ang2=(2*pi/7)

# Para s=182
#Fourier k=1 
energia_copia$sin = sin(c(1:5054)*(1*frec_ang))
energia_copia$cos = cos(c(1:5054)*(1*frec_ang))

#Fourier k=2 
energia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))
energia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))

#Fourier k=3 
energia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))
energia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))

# Para s=7
#Fourier k=1 
energia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))
energia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))

#Fourier k=2 
energia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))
energia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))

#Fourier k=3 
energia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))
energia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))

linmodel_ciclo<-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)

results_ciclo=linmodel_ciclo$fitted.values
results_ciclo<-as.data.frame(results_ciclo)
results_ciclo_ts<-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)
```

```{r}
#| echo: false
# Rolling
#fcmat=matrix(0,nrow=ntest,ncol=h)
#for(i in 1:ntest){
#  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)
#  refit=Arima(x,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)#,method = c("CSS-ML"))
#  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pron√≥sticos #para datos estacionarios
#}
```

```{r}
#| warning: false
# Rolling corregido
fcmat=matrix(0,nrow=ntest,ncol=h)
for(i in 1:ntest){
  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)
  refit=Arima(x,model=modelo.propuesto2)
  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pron√≥sticos para datos estacionarios
}
```

```{r}
#| echo: false
# Esto es para no estar leyendo ese rolling todo el tiempo
#saveRDS(fcmat, file="pron_est.RDS")
fcmat<-readRDS("pron_est.RDS")
```

```{r}
# Para volver a la escala original
estacionalidad<-as.vector(results_ciclo_ts)
tendencia<-as.vector(predict(fit_e))
fchstepahe<-(fcmat+estacionalidad[4296:5054])+tendencia[4296:5054] # primero sumamos la estacionalidad y luego la tendencia

errores_pred = verval-fchstepahe 
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)
RECM=sqrt(ECM)
RECM # 22840.1
```

#### Predicciones sobre datos de prueba

```{r}
fchstepahe_ts<-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)

plot(verval_ts, col = "blue", ylab = "Energ√≠a", xlab = "Tiempo")
lines(fchstepahe_ts, col = "red")
legend("topright", legend = c("Reales", "Predicciones"), col = c("blue", "red"), lty = 1)
```

## Proceso ARIMA

Para ajustar un modelo ARIMA (aunque no es lo m√°s adecuado dado que la serie presenta componente estacional), primero se debe comprobar si la serie de tiempo presenta una ra√≠z unitaria. Teniendo en cuenta que, para la prueba de Dicker Fuller, si el $p-valor$ es menor que un nivel de significancia $\alpha$ se rechaza la hipotesis nula de que la serie de tiempo presenta una ra√≠z unitaria, se tiene lo siguiente.

```{r}
stats::ar(energia2) # Selecciona un modelo AR usando el criterio de Akaike, sugiere tomar lags=36
tseries::adf.test(energia2,k=36) # Prueba Dicker Fuller: No hay ra√≠z unitaria
summary(ur.df(energia2,type="trend",lags = 36))
```

Como se puede ver, en ambos casos las pruebas muestran que la serie no presenta ra√≠ces unitarias, por lo que ajustar este modelo no es adecuado.

## Proceso SARIMA

Dado que la serie presenta multiple estacionalidad, no es posible ajustar un modelo de la familia SARIMA.
